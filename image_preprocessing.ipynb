{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7_MgqZAFck2",
        "outputId": "b9723e1f-505e-4d93-c7ec-02db83ec8093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X12q0n5mUWFs"
      },
      "source": [
        "# Using paddleocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM5Q7fVE9zlw",
        "outputId": "caeb42ca-3d4c-4f8f-9ea7-75314696a1f8"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle\n",
        "!pip install paddleocr==2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "p1MduXwjHjwi",
        "outputId": "40779adb-a0da-4841-87a8-55b0fa49745e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!pip install segmentation_models==1.0.1\n",
        "!pip install simple-lama-inpainting\n",
        "os._exit(0)\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.25.2\n",
        "os._exit(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TgEdsZYcpeJA",
        "outputId": "fed7ec99-8e16-4059-907b-404da894a013"
      },
      "outputs": [],
      "source": [
        "!unzip \"<contact_to_our_corresponding_email>\" -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Gj1NR4CEjk7e",
        "outputId": "34ebe87a-0533-4395-ba53-eeb0da1a94da"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from simple_lama_inpainting import SimpleLama\n",
        "import time\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Hide all GPUs\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Reduce TensorFlow logging\n",
        "os.environ[\"FLAGS_fraction_of_gpu_memory_to_use\"] = \"0.0\"  # Don't use GPU memory for Paddle\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"  # For segmentation models\n",
        "\n",
        "import tensorflow as tf\n",
        "import paddle\n",
        "import segmentation_models as sm\n",
        "\n",
        "paddle.set_device('cpu')\n",
        "sm.set_framework('tf.keras')\n",
        "\n",
        "from paddleocr import PaddleOCR\n",
        "\n",
        "VIS_DIR = \"pipeline_viz\"\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "LEFT_CUT_SIZE = 0.235\n",
        "RIGHT_CUT_SIZE = 0.945\n",
        "\n",
        "simple_lama = SimpleLama()\n",
        "\n",
        "class EndoscopyImageProcessor:\n",
        "    def __init__(self):\n",
        "        base_dir = os.getcwd()\n",
        "\n",
        "        # Create output directories structure\n",
        "        masks_root = os.path.join(base_dir, \"masks\")\n",
        "        os.makedirs(masks_root, exist_ok=True)\n",
        "\n",
        "        self.output_folder_masks = {\n",
        "            \"highlight\": os.path.join(masks_root, \"highlight_masks\"),\n",
        "            \"instrument\": os.path.join(masks_root, \"instrument_masks\"),\n",
        "            \"textbox\":    os.path.join(masks_root, \"textbox_masks\"),\n",
        "            \"combined\":   os.path.join(masks_root, \"combined_masks\"),\n",
        "            \"black_frame\":os.path.join(masks_root, \"black_frame_masks\")\n",
        "        }\n",
        "\n",
        "        self.output_folder_processed = os.path.join(base_dir, \"processed_images\")\n",
        "        self.output_folder_comparison = os.path.join(base_dir, \"comparison_images\")\n",
        "\n",
        "        # Create all directories\n",
        "        for folder in self.output_folder_masks.values():\n",
        "            os.makedirs(folder, exist_ok=True)\n",
        "        os.makedirs(self.output_folder_processed, exist_ok=True)\n",
        "        os.makedirs(self.output_folder_comparison, exist_ok=True)\n",
        "\n",
        "        self.ocr_engine = None\n",
        "        self.instrument_model = None\n",
        "\n",
        "        self.simple_lama = SimpleLama()\n",
        "\n",
        "    def load_ocr_engine(self):\n",
        "        \"\"\"Lazy loading for OCR engine on CPU\"\"\"\n",
        "        if self.ocr_engine is None:\n",
        "\n",
        "            if hasattr(tf.keras.backend, 'clear_session'):\n",
        "                tf.keras.backend.clear_session()\n",
        "            gc.collect()\n",
        "\n",
        "            self.ocr_engine = PaddleOCR(\n",
        "                use_angle_cls=True,   # Disable angle classifier to avoid warnings\n",
        "                lang='en',\n",
        "                show_log=False\n",
        "            )\n",
        "\n",
        "    def load_instrument_detector(self):\n",
        "        \"\"\"\n",
        "        Lazy-load model, khắc phục lỗi 'groups' và tránh compile.\n",
        "        \"\"\"\n",
        "        if self.instrument_model is not None:\n",
        "            return\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        def dice_coef(y_true, y_pred):\n",
        "            y_true_f = tf.keras.backend.flatten(y_true)\n",
        "            y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "            inter    = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "            return (2. * inter + 1) / (tf.keras.backend.sum(y_true_f) +\n",
        "                                      tf.keras.backend.sum(y_pred_f) + 1)\n",
        "\n",
        "        def dice_coef_loss(y_true, y_pred):\n",
        "            return -dice_coef(y_true, y_pred)\n",
        "\n",
        "        from tensorflow.keras.layers import Conv2DTranspose as KConv2DT\n",
        "\n",
        "        class Conv2DTransposeCompat(KConv2DT):\n",
        "            def __init__(self, *args, groups=1, **kwargs):\n",
        "                super().__init__(*args, **kwargs)\n",
        "\n",
        "            @classmethod\n",
        "            def from_config(cls, config):\n",
        "                config.pop(\"groups\", None)\n",
        "                return super().from_config(config)\n",
        "\n",
        "        model_path = \"<contact_to_our_corresponding_email>\"\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"Không tìm thấy model: {model_path}\")\n",
        "\n",
        "        from tensorflow.keras.models import load_model\n",
        "        with tf.device('/CPU:0'):\n",
        "          self.instrument_model = load_model(\n",
        "              model_path,\n",
        "              custom_objects={\n",
        "                  \"dice_coef\":        dice_coef,\n",
        "                  \"dice_coef_loss\":   dice_coef_loss,\n",
        "                  \"Conv2DTranspose\":  Conv2DTransposeCompat\n",
        "              },\n",
        "              compile=False            # <-- quan trọng\n",
        "          )\n",
        "          self.instrument_model.make_predict_function()\n",
        "\n",
        "    def get_outliers(self, data, m=17.):\n",
        "        \"\"\"Find outliers in data using median absolute deviation\"\"\"\n",
        "        if len(data) == 0:\n",
        "            return np.array([])\n",
        "\n",
        "        data = np.array(data)\n",
        "        d = np.abs(data - np.median(data))\n",
        "        mdev = np.median(d)\n",
        "\n",
        "        if mdev == 0:\n",
        "            return np.array([])\n",
        "\n",
        "        s = d / mdev\n",
        "        return data[s >= m]\n",
        "\n",
        "    def create_highlight_mask(self, image):\n",
        "        grey = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        _, thresh = cv2.threshold(grey, 220, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        thresh_dilated = cv2.dilate(thresh.copy(), None, iterations=3)\n",
        "\n",
        "        contours, _ = cv2.findContours(thresh_dilated.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if not contours:\n",
        "            return np.zeros_like(grey)\n",
        "\n",
        "        a0 = [cv2.contourArea(contour) for contour in contours]\n",
        "        outlier_areas = [i for i in self.get_outliers(a0) if i > 7500]\n",
        "        mask_after_removal = thresh_dilated.copy()\n",
        "\n",
        "        if outlier_areas:\n",
        "            outlier_indices = [a0.index(i) for i in outlier_areas if i in a0]\n",
        "            for i in outlier_indices:\n",
        "                if 0 <= i < len(contours):\n",
        "                    mask_after_removal = cv2.drawContours(mask_after_removal, [contours[i]], -1, (0, 0, 0), -1)\n",
        "\n",
        "        mask_eroded = cv2.erode(mask_after_removal.copy(), None, iterations=3)\n",
        "        final_mask = cv2.dilate(mask_eroded.copy(), None, iterations=2)\n",
        "\n",
        "        return final_mask\n",
        "\n",
        "    def create_instrument_mask(self, image):\n",
        "        \"\"\"Create instrument mask from input image\"\"\"\n",
        "        self.load_instrument_detector()\n",
        "        model = self.instrument_model\n",
        "\n",
        "        input_h, input_w = 256, 256  # Based on the model definition\n",
        "\n",
        "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        img_resized = cv2.resize(img_rgb, (input_w, input_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        img_normalized = img_resized / 255.0\n",
        "\n",
        "        img_input = np.expand_dims(img_normalized, axis=0)  # shape: (1, 256, 256, 3)\n",
        "        # Predict mask\n",
        "        prediction = model.predict_on_batch(img_input)\n",
        "\n",
        "        predicted_mask = np.mean(prediction[0], axis=2)\n",
        "\n",
        "        # Apply thresholding to get binary mask\n",
        "        binary_mask = (predicted_mask > 0.5).astype(np.float32)\n",
        "\n",
        "        # Resize mask back to original image dimensions\n",
        "        mask_final = cv2.resize(binary_mask, (image.shape[1], image.shape[0]),\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        # Convert to 8-bit format for visualization\n",
        "        return (mask_final * 255).astype(np.uint8)\n",
        "\n",
        "    def create_textbox_mask(self, image_path):\n",
        "        \"\"\"Create text mask using PaddleOCR\"\"\"\n",
        "        # Memory cleanup before OCR\n",
        "        if hasattr(tf.keras.backend, 'clear_session'):\n",
        "            tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "        # Ensure OCR engine is loaded\n",
        "        self.load_ocr_engine()\n",
        "\n",
        "        # Read image\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return np.zeros((100, 100), dtype=np.uint8)\n",
        "\n",
        "        # Create empty mask with same dimensions as image\n",
        "        mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "\n",
        "        # Run OCR detection\n",
        "        result = self.ocr_engine.ocr(img, cls=True)\n",
        "\n",
        "        # Check for valid results\n",
        "        if result is None or len(result) == 0 or not result[0]:\n",
        "            return mask  # Return empty mask if no text is detected\n",
        "\n",
        "        # Process detected text regions\n",
        "        for line in result[0]:\n",
        "            if line and len(line) > 1:\n",
        "                bbox = line[0]  # Get the bounding box of the text\n",
        "\n",
        "                # Validate bbox structure and draw the polygon\n",
        "                if len(bbox) == 4 and all(isinstance(pt, (list, tuple)) and len(pt) == 2 for pt in bbox):\n",
        "                    pts = np.array(bbox, dtype=np.int32)\n",
        "                    cv2.fillPoly(mask, [pts], 255)  # Fill the detected text area in the mask\n",
        "\n",
        "        # Memory cleanup after OCR\n",
        "        gc.collect()\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def detect_green_box(self, image):\n",
        "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        lower_green = np.array([35, 50, 40])\n",
        "        upper_green = np.array([85, 255, 255])\n",
        "\n",
        "        # Create mask for green color range\n",
        "        mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
        "\n",
        "        # Morphological operations to clean the mask\n",
        "        kernel = np.ones((5, 5), np.uint8)\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def combine_masks(self, highlight_mask, instrument_mask, textbox_mask, green_box_mask=None):\n",
        "        h, w = highlight_mask.shape[:2]\n",
        "\n",
        "        instrument_mask_resized = cv2.resize(instrument_mask, (w, h))\n",
        "        textbox_mask_resized = cv2.resize(textbox_mask, (w, h))\n",
        "\n",
        "        exclude_mask = cv2.bitwise_or(instrument_mask_resized, textbox_mask_resized)\n",
        "\n",
        "        if green_box_mask is not None:\n",
        "            green_box_resized = cv2.resize(green_box_mask, (w, h))\n",
        "            exclude_mask = cv2.bitwise_or(exclude_mask, green_box_resized)\n",
        "\n",
        "        combined_mask = cv2.bitwise_and(highlight_mask, cv2.bitwise_not(exclude_mask))\n",
        "\n",
        "        return combined_mask\n",
        "\n",
        "    # === IMAGE PROCESSING FUNCTIONS ===\n",
        "\n",
        "    def simple_inpaint_highlight(self, image, mask, method=cv2.INPAINT_TELEA):\n",
        "        blur = np.copy(image)\n",
        "        for i in range(20):\n",
        "            mask = cv2.GaussianBlur(mask, (3, 3), 3)\n",
        "            blur = cv2.GaussianBlur(blur, (3, 3), 3)\n",
        "        image[mask > 0] = blur[mask > 0]\n",
        "        return cv2.inpaint(image, mask, 3, flags=cv2.INPAINT_NS)\n",
        "\n",
        "    def simple_inpaint_border(self, image, mask,\n",
        "                              morph_k=15, dilate_k=31, dilate_iter=1, feather_k=31):\n",
        "        # 1) Chuẩn bị image RGB và mask nhị phân\n",
        "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        h, w = img_rgb.shape[:2]\n",
        "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY) \\\n",
        "                    if mask.ndim==3 else mask\n",
        "        _, mask_bin = cv2.threshold(mask_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "        mask_bin = cv2.resize(mask_bin, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # 2) Morphological closing (điền kín các góc lõm)\n",
        "        ellip = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (morph_k, morph_k))\n",
        "        mask_closed = cv2.morphologyEx(mask_bin, cv2.MORPH_CLOSE, ellip)\n",
        "\n",
        "        # 3) Dilate để “ăn sâu” thêm vào trong\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (dilate_k, dilate_k))\n",
        "        mask_dilated = cv2.dilate(mask_closed, kernel, iterations=dilate_iter)\n",
        "\n",
        "        # 4) Inpaint với Simple-LaMa\n",
        "        pil_img  = Image.fromarray(img_rgb)\n",
        "        pil_mask = Image.fromarray(mask_dilated)\n",
        "        inpainted_pil = self.simple_lama(pil_img, pil_mask)\n",
        "        inpainted_rgb = np.array(inpainted_pil)\n",
        "        if inpainted_rgb.shape[:2] != (h, w):\n",
        "            inpainted_rgb = cv2.resize(inpainted_rgb, (w, h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        # 5) Tạo soft mask và blend\n",
        "        mask_f = mask_dilated.astype(np.float32) / 255.0\n",
        "        soft = cv2.GaussianBlur(mask_f, (feather_k, feather_k), 0)\n",
        "        soft = soft[...,None]      # shape (h,w,1)\n",
        "        result_rgb = (img_rgb*(1-soft) + inpainted_rgb*soft).astype(np.uint8)\n",
        "\n",
        "        # 6) Trả về BGR\n",
        "        return cv2.cvtColor(result_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    def restore_text_without_black(self, processed_img, original_img, text_mask):\n",
        "\n",
        "        result = processed_img.copy()\n",
        "\n",
        "        original_hsv = cv2.cvtColor(original_img, cv2.COLOR_BGR2HSV)\n",
        "        v_channel = original_hsv[:, :, 2]  # Value channel in HSV\n",
        "\n",
        "        non_black_mask = (v_channel > 30) & (text_mask > 0)\n",
        "\n",
        "        result[non_black_mask] = original_img[non_black_mask]\n",
        "\n",
        "        return result\n",
        "\n",
        "    # === BLACK FRAME DETECTION AND REMOVAL ===\n",
        "\n",
        "    def process_border_width(self, c, c1):\n",
        "        \"\"\"Calculate border width based on two detections\"\"\"\n",
        "        if c1 <= 1 and c <= 1:\n",
        "            return 5\n",
        "        return c1 - c + 6\n",
        "\n",
        "    def get_border_width(self, thresh0):\n",
        "        thresh1 = thresh0\n",
        "        tmpw1 = thresh1[int(thresh1.shape[0] * 0.5):int(thresh1.shape[0] * 0.6), :]\n",
        "        tmph1 = thresh1[:, int(thresh1.shape[1] * 0.25):int(thresh1.shape[1] * 0.75)]\n",
        "        cl1 = [i for i in range(tmpw1.shape[1]) if 0 in tmpw1[:, i]][0]\n",
        "        cr1 = tmpw1.shape[1] - [i for i in range(tmpw1.shape[1]) if 0 in tmpw1[:, i]][-1]\n",
        "        ct1 = [i for i in range(tmph1.shape[0]) if 0 in tmph1[i, :]][0]\n",
        "        cb1 = tmph1.shape[0] - [i for i in range(tmph1.shape[0]) if 0 in tmph1[i, :]][-1]\n",
        "\n",
        "\n",
        "        thresh1 = cv2.erode(thresh0, None, iterations=5)\n",
        "        tmpw = thresh1[int(thresh1.shape[0] * 0.5):int(thresh1.shape[0] * 0.6), :]\n",
        "        tmph = thresh1[:, int(thresh1.shape[1] * 0.25):int(thresh1.shape[1] * 0.75)]\n",
        "        cl = [i for i in range(tmpw.shape[1]) if 0 in tmpw[:, i]][0]\n",
        "        cr = tmpw.shape[1] - [i for i in range(tmpw.shape[1]) if 0 in tmpw[:, i]][-1]\n",
        "        ct = [i for i in range(tmph.shape[0]) if 0 in tmph[i, :]][0]\n",
        "        cb = tmph.shape[0] - [i for i in range(tmph.shape[0]) if 0 in tmph[i, :]][-1]\n",
        "\n",
        "        # Process border widths\n",
        "        cl += self.process_border_width(cl, cl1)\n",
        "        cr += self.process_border_width(cr, cr1) + 2\n",
        "        ct += self.process_border_width(ct, ct1)\n",
        "        cb += self.process_border_width(cb, cb1)\n",
        "\n",
        "        return int(cl), int(cr), int(ct), int(cb), thresh1\n",
        "\n",
        "    def get_corner_width(self, thresh0):\n",
        "        diag1 = np.diag(thresh0)\n",
        "        diag2 = np.diag(np.fliplr(thresh0))\n",
        "        ctl = [i for i in range(len(diag1)) if diag1[i] == 0][0]\n",
        "        cbr = len(diag1) - [i for i in range(len(diag1)) if diag1[i] == 0][-1]\n",
        "        ctr = [i for i in range(len(diag2)) if diag2[i] == 0][0]\n",
        "        cbl = len(diag2) - [i for i in range(len(diag2)) if diag2[i] == 0][-1]\n",
        "        return ctl, ctr, cbl, cbr\n",
        "\n",
        "    def preprocess_border_mask1(self, image, thresh0):\n",
        "        FLAG = 0\n",
        "\n",
        "        cl, cr, ct, cb, thresh1 = self.get_border_width(thresh0)\n",
        "\n",
        "        # Tạo hình chữ nhật trắng trên nền đen\n",
        "        rectangle = 255 * np.ones(thresh0.shape, dtype=\"uint8\")\n",
        "        cv2.rectangle(rectangle, (cl, ct), (thresh0.shape[1] - cr, thresh0.shape[0] - cb), 0, -1)\n",
        "        # Tạo hình oval trắng trên nền đen\n",
        "        oval = 255 * np.ones(thresh0.shape, dtype=\"uint8\")\n",
        "        center = (int((cl + thresh0.shape[1] - cr) / 2), int((ct + thresh0.shape[0] - cb) / 2))\n",
        "        axes = (int((thresh0.shape[1] - cl - cr) / 2 * 1.08), int((thresh0.shape[0] - ct - cb) / 2 * 1.18))\n",
        "        cv2.ellipse(oval, center, axes, 0, 0, 360, 0, -1)\n",
        "\n",
        "        # Kết hợp hình chữ nhật và oval\n",
        "        border_mask = cv2.bitwise_or(rectangle, oval)\n",
        "        try:\n",
        "            ctl, ctr, cbl, cbr = self.get_corner_width(thresh0)\n",
        "        except IndexError:\n",
        "            ctl, ctr, cbl, cbr = 0, 0, 0, 0\n",
        "\n",
        "        white_rect_width = thresh0.shape[1] - cl - cr\n",
        "        white_rect_height = thresh0.shape[0] - ct - cb\n",
        "        white_rect_area = white_rect_width * white_rect_height\n",
        "        black_rect_size = (border_mask.shape[0] // 3, border_mask.shape[1] // 3)\n",
        "        triangle_area = white_rect_area / 19\n",
        "        triangle_base_height = int(np.sqrt(2 * triangle_area))\n",
        "        triangle_area2 = white_rect_area / 16\n",
        "        triangle_base_height2 = int(np.sqrt(2 * triangle_area2))\n",
        "        triangle_area3 = white_rect_area / 13\n",
        "        triangle_base_height3 = int(np.sqrt(2 * triangle_area3))\n",
        "        triangle_area4 = white_rect_area / 10\n",
        "        triangle_base_height4 = int(np.sqrt(2 * triangle_area4))\n",
        "        # Góc trên trái\n",
        "        if ctl > 0 and ctl < 36 and border_mask[ctl, ctl] == 0:\n",
        "            pts = np.array([[0, 0], [triangle_base_height, 0], [0, triangle_base_height]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif ctl >= 36 and ctl < 46 and border_mask[ctl, ctl] == 0:\n",
        "            pts = np.array([[0, 0], [triangle_base_height2, 0], [0, triangle_base_height2]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif ctl >= 46 and ctl < 55 and border_mask[ctl, ctl] == 0:\n",
        "            pts = np.array([[0, 0], [triangle_base_height3, 0], [0, triangle_base_height3]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif ctl >= 55 and border_mask[ctl, ctl] == 0:\n",
        "            pts = np.array([[0, 0], [triangle_base_height4, 0], [0, triangle_base_height4]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        # Góc trên phải\n",
        "        if ctr > 0 and ctr < 36 and border_mask[ctr, border_mask.shape[1] - ctr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, 0], [border_mask.shape[1] - 1 - triangle_base_height, 0], [border_mask.shape[1] - 1, triangle_base_height]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif ctr >= 36 and ctr < 46 and border_mask[ctr, border_mask.shape[1] - ctr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, 0], [border_mask.shape[1] - 1 - triangle_base_height2, 0], [border_mask.shape[1] - 1, triangle_base_height2]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif ctr >= 46 and ctr < 55 and border_mask[ctr, border_mask.shape[1] - ctr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, 0], [border_mask.shape[1] - 1 - triangle_base_height3, 0], [border_mask.shape[1] - 1, triangle_base_height3]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif ctr >= 55 and border_mask[ctr, border_mask.shape[1] - ctr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, 0], [border_mask.shape[1] - 1 - triangle_base_height4, 0], [border_mask.shape[1] - 1, triangle_base_height4]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        # Góc dưới trái\n",
        "        if cbl > 0 and cbl < 50 and border_mask[border_mask.shape[0] - cbl - 1, cbl] == 0:\n",
        "            pts = np.array([[0, border_mask.shape[0] - 1], [triangle_base_height2, border_mask.shape[0] - 1], [0, border_mask.shape[0] - 1 - triangle_base_height2]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        # Góc dưới phải\n",
        "        if cbr > 0 and cbr < 36 and border_mask[border_mask.shape[0] - cbr - 1, border_mask.shape[1] - cbr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, border_mask.shape[0] - 1], [border_mask.shape[1] - 1 - triangle_base_height, border_mask.shape[0] - 1], [border_mask.shape[1] - 1, border_mask.shape[0] - 1 - triangle_base_height]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif cbr >= 36 and cbr < 46 and border_mask[border_mask.shape[0] - cbr - 1, border_mask.shape[1] - cbr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, border_mask.shape[0] - 1], [border_mask.shape[1] - 1 - triangle_base_height2, border_mask.shape[0] - 1], [border_mask.shape[1] - 1, border_mask.shape[0] - 1 - triangle_base_height2]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif cbr >= 46 and cbr < 55 and border_mask[border_mask.shape[0] - cbr - 1, border_mask.shape[1] - cbr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, border_mask.shape[0] - 1], [border_mask.shape[1] - 1 - triangle_base_height3, border_mask.shape[0] - 1], [border_mask.shape[1] - 1, border_mask.shape[0] - 1 - triangle_base_height3]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        elif cbr >= 55 and border_mask[border_mask.shape[0] - cbr - 1, border_mask.shape[1] - cbr - 1] == 0:\n",
        "            pts = np.array([[border_mask.shape[1] - 1, border_mask.shape[0] - 1], [border_mask.shape[1] - 1 - triangle_base_height4, border_mask.shape[0] - 1], [border_mask.shape[1] - 1, border_mask.shape[0] - 1 - triangle_base_height4]])\n",
        "            cv2.fillPoly(border_mask, [pts], 255)\n",
        "        # Phát hiện black box ở góc dưới trái\n",
        "        if cbl > 0 and cbl >= 50 and border_mask[border_mask.shape[0] - cbl - 1, cbl] == 0:\n",
        "            black_rect = np.zeros(black_rect_size, dtype=\"uint8\")\n",
        "            border_mask[border_mask.shape[0] - cb - black_rect_size[0]:border_mask.shape[0] - cb, cl:cl + black_rect_size[1]] = black_rect\n",
        "\n",
        "        # Phát hiện và xử lý các vùng màu xanh lá cây\n",
        "        green_mask = self.detect_green_box(image)\n",
        "        height, width = green_mask.shape\n",
        "        if np.any(green_mask[int(height * 0.75):, :int(width * 0.25)] == 255):\n",
        "            black_rect = np.zeros((triangle_base_height, triangle_base_height), dtype=\"uint8\")\n",
        "            border_mask[border_mask.shape[0] - cb - triangle_base_height:border_mask.shape[0] - cb,\n",
        "                        cl:cl + triangle_base_height] = black_rect\n",
        "\n",
        "        return border_mask, None, cl, cr, ct, cb, ctl, ctr, cbl, cbr, thresh1, green_mask, FLAG\n",
        "\n",
        "    def create_text_mask_from_threshold(self, thresh_image, left_crop_ratio=LEFT_CUT_SIZE):\n",
        "        thresh_image_copy = np.copy(thresh_image)\n",
        "\n",
        "        width = thresh_image_copy.shape[1]\n",
        "        left_crop = int(width * left_crop_ratio)\n",
        "\n",
        "        thresh_image_copy[:, left_crop:] = 255\n",
        "\n",
        "        return thresh_image_copy\n",
        "\n",
        "    def preprocess_border_mask_rectangle(self, image, thresh0):\n",
        "\n",
        "        FLAG = 0\n",
        "\n",
        "        cl, cr, ct, cb, thresh1 = self.get_border_width(thresh0)\n",
        "        rectangle = 255 * np.ones(thresh0.shape, dtype=\"uint8\")\n",
        "        cv2.rectangle(rectangle, (cl, ct), (thresh0.shape[1] - cr, thresh0.shape[0] - cb), 0, -1)\n",
        "        oval = 255 * np.ones(thresh0.shape, dtype=\"uint8\")\n",
        "        center = (int((cl + thresh0.shape[1] - cr) / 2), int((ct + thresh0.shape[0] - cb) / 2))\n",
        "        axes = (int((thresh0.shape[1] - cl - cr) / 2 * 1.08), int((thresh0.shape[0] - ct - cb) / 2 * 1.18))\n",
        "        cv2.ellipse(oval, center, axes, 0, 0, 360, 0, -1)\n",
        "        border_mask = cv2.bitwise_or(rectangle, oval)\n",
        "\n",
        "        if border_mask.shape == (1072, 1920):\n",
        "          FLAG = 1\n",
        "          border_mask = border_mask[:, int(border_mask.shape[1] * LEFT_CUT_SIZE):int(border_mask.shape[1] * RIGHT_CUT_SIZE)]\n",
        "        return border_mask, None, cl, cr, ct, cb, thresh1, FLAG\n",
        "\n",
        "    def create_rectangle_mask(self, image_path,\n",
        "                              min_area        = 100,\n",
        "                              max_area_ratio  = 0.5,\n",
        "                              corner_tol_ratio= 0.04):   # 5 % kích thước ảnh\n",
        "        \"\"\"\n",
        "        Chỉ detect hình vuông/chữ nhật ở góc trái trên và\n",
        "        diện tích < 50 % ảnh.\n",
        "        \"\"\"\n",
        "        image = cv2.imread(image_path)\n",
        "        gray  = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        blur  = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "        _, thresh = cv2.threshold(blur, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "        contours, _ = cv2.findContours(thresh,\n",
        "                                      cv2.RETR_EXTERNAL,\n",
        "                                      cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        h, w = gray.shape\n",
        "        img_area   = h * w\n",
        "        tol_x      = int(w * corner_tol_ratio)   # sai số mép trái\n",
        "        tol_y      = int(h * corner_tol_ratio)   # sai số mép trên\n",
        "\n",
        "        mask            = np.zeros_like(gray)\n",
        "        detected_shapes = []\n",
        "\n",
        "        for cnt in contours:\n",
        "            area = cv2.contourArea(cnt)\n",
        "            if area < min_area or area > max_area_ratio * img_area:\n",
        "                continue\n",
        "\n",
        "            peri   = cv2.arcLength(cnt, True)\n",
        "            approx = cv2.approxPolyDP(cnt, 0.04 * peri, True)\n",
        "\n",
        "            if len(approx) != 4:\n",
        "                continue                                    # không phải tứ giác\n",
        "\n",
        "            x, y, bw, bh = cv2.boundingRect(approx)\n",
        "\n",
        "            # ---- CHỈ NHẬN BOX Ở GÓC DƯỚI ----\n",
        "            is_left_edge = x <= tol_x\n",
        "            is_bottom_edge = y + bh >= h - tol_y\n",
        "            if not (is_left_edge and is_bottom_edge):\n",
        "                continue\n",
        "            # --------------------------------------\n",
        "\n",
        "            cv2.rectangle(mask, (x, y), (x + bw, y + bh), 255, -1)\n",
        "\n",
        "            aspect = bw / float(bh)\n",
        "            detected_shapes.append({\n",
        "                'type'         : 'Square' if 0.9 <= aspect <= 1.1 else 'Rectangle',\n",
        "                'coordinates'  : (x, y, bw, bh),\n",
        "                'area'         : int(area),\n",
        "                'position'     : 'bottem‑Left'\n",
        "            })\n",
        "\n",
        "        return mask, detected_shapes\n",
        "\n",
        "    # === IMAGE PROCESSING PIPELINE ===\n",
        "\n",
        "    def process_image(self, image_path):\n",
        "        # Read image\n",
        "        orig = cv2.imread(image_path)\n",
        "\n",
        "        h0, w0 = orig.shape[:2]\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        orig_backup = orig.copy()\n",
        "\n",
        "        # Create textbox mask\n",
        "        textbox_mask = self.create_textbox_mask(image_path)\n",
        "        textbox_mask = cv2.resize(textbox_mask, (w0, h0), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        if np.any(textbox_mask):\n",
        "            text_content = cv2.bitwise_and(orig_backup, orig_backup, mask=textbox_mask)\n",
        "        else:\n",
        "            text_content = None\n",
        "\n",
        "        highlight_mask = self.create_highlight_mask(orig)\n",
        "\n",
        "        # Free memory before instrument detection\n",
        "        gc.collect()\n",
        "\n",
        "        instrument_mask = self.create_instrument_mask(orig)\n",
        "\n",
        "        exclude_mask = (cv2.bitwise_or(instrument_mask, textbox_mask)\n",
        "                       if textbox_mask is not None else instrument_mask)\n",
        "\n",
        "        final_highlight_mask = cv2.bitwise_and(\n",
        "            highlight_mask, cv2.bitwise_not(exclude_mask))\n",
        "\n",
        "        img_no_highlight = self.simple_inpaint_highlight(orig.copy(), final_highlight_mask)\n",
        "\n",
        "        # Free memory before border processing\n",
        "        gc.collect()\n",
        "\n",
        "        # — PHASE 2: Black-frame removal\n",
        "        threshold = 80\n",
        "        img_border = np.copy(img_no_highlight)\n",
        "        if img_no_highlight.shape != (1072, 1920, 3):\n",
        "          img_border = cv2.resize(img_border, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "          threshold = 10\n",
        "\n",
        "        gray = cv2.cvtColor(img_border, cv2.COLOR_BGR2GRAY)\n",
        "        _, th0 = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "        mask, detected_shapes = self.create_rectangle_mask(image_path)\n",
        "\n",
        "        mask = cv2.bitwise_not(mask)\n",
        "\n",
        "        if mask.shape != th0.shape:\n",
        "          mask = cv2.resize(mask, (th0.shape[1], th0.shape[0]))\n",
        "\n",
        "        th0 = cv2.bitwise_and(th0, mask)\n",
        "\n",
        "        if img_no_highlight.shape != (1072, 1920, 3):\n",
        "          border_mask, _, cl, cr, ct, cb, ctl, ctr, cbl, cbr, thresh1, green_mask, flag = self.preprocess_border_mask1(img_border, th0)\n",
        "        else:\n",
        "          border_mask, _, cl, cr, ct, cb, thresh1, flag = self.preprocess_border_mask_rectangle(img_border, th0)\n",
        "\n",
        "        if 0 in mask:\n",
        "          border_mask = cv2.bitwise_and(border_mask, mask)\n",
        "\n",
        "        if flag == 1:\n",
        "            image_copy_1 = np.copy(img_no_highlight)\n",
        "            image_copy_2 = np.copy(img_no_highlight)\n",
        "            image_copy_1 = image_copy_1[:, int(image_copy_1.shape[1] * LEFT_CUT_SIZE):int(image_copy_1.shape[1] * RIGHT_CUT_SIZE)]\n",
        "            image_copy_2 = image_copy_2[:, :int(image_copy_2.shape[1]) - int(image_copy_2.shape[1] * 0.2905)]\n",
        "            text_mask = self.create_text_mask_from_threshold(th0)\n",
        "            textbox_mask = text_mask[:, :int(text_mask.shape[1]) - int(text_mask.shape[1] * 0.2905)]\n",
        "            inpainted_image = self.simple_inpaint_border(image_copy_1, border_mask)\n",
        "            image_copy_3 = cv2.cvtColor(image_copy_1, cv2.COLOR_BGR2RGB)\n",
        "            img_no_blackframe = inpainted_image.copy()\n",
        "            final_img = image_copy_2.copy()\n",
        "            final_img[textbox_mask > 0] = img_no_blackframe[textbox_mask > 20]\n",
        "\n",
        "        else:\n",
        "            border_mask_resized = cv2.resize(border_mask, (img_no_highlight.shape[1], img_no_highlight.shape[0]))\n",
        "            img_no_blackframe = self.simple_inpaint_border(img_no_highlight, border_mask_resized)\n",
        "            final_img = img_no_blackframe.copy()\n",
        "            if textbox_mask is not None and flag != 1:\n",
        "                final_img = self.restore_text_without_black(\n",
        "                    final_img, orig_backup, textbox_mask)\n",
        "\n",
        "        # Clean up memory\n",
        "        gc.collect()\n",
        "        if flag == 1:\n",
        "          green_mask = cv2.bitwise_not(image_copy_1)\n",
        "          mask = image_copy_2\n",
        "\n",
        "        return orig, highlight_mask, instrument_mask, textbox_mask, mask, cv2.bitwise_not(green_mask), final_highlight_mask, img_no_highlight, th0, border_mask, img_no_blackframe, final_img\n",
        "\n",
        "    def visualize_pipeline(self, image_path):\n",
        "        \"\"\"\n",
        "        Visualize and save each intermediate result from process_image side by side.\n",
        "        \"\"\"\n",
        "        import os\n",
        "        import time\n",
        "        import cv2\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Run full processing\n",
        "        (orig,\n",
        "        highlight_mask,\n",
        "        instrument_mask,\n",
        "        textbox_mask,\n",
        "        box_mask,\n",
        "        green_mask,\n",
        "        final_highlight_mask,\n",
        "        img_no_highlight,\n",
        "        th0,\n",
        "        border_mask,\n",
        "        img_no_blackframe,\n",
        "        final_img) = self.process_image(image_path)\n",
        "\n",
        "        # Prepare output directories\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        subdirs = {\n",
        "            'original': orig,\n",
        "            'highlight_mask': highlight_mask,\n",
        "            'instrument_mask': instrument_mask,\n",
        "            'textbox_mask': textbox_mask,\n",
        "            'box_mask': box_mask,\n",
        "            'green_mask': green_mask,\n",
        "            'final_highlight_mask': final_highlight_mask,\n",
        "            'th0': th0,\n",
        "            'border_mask': border_mask,\n",
        "            'img_no_highlight': img_no_highlight,\n",
        "            'img_no_blackframe': img_no_blackframe,\n",
        "            'final_restored': final_img,\n",
        "        }\n",
        "\n",
        "        # ensure base viz folder exists\n",
        "        os.makedirs(VIS_DIR, exist_ok=True)\n",
        "        for name in subdirs:\n",
        "            d = os.path.join(VIS_DIR, name)\n",
        "            os.makedirs(d, exist_ok=True)\n",
        "            path = os.path.join(d, f\"{base_name}.png\")\n",
        "            # convert masks/th if needed to 3-channel images\n",
        "            img = subdirs[name]\n",
        "            if len(img.shape) == 2:\n",
        "                img_to_save = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "            else:\n",
        "                img_to_save = img\n",
        "            cv2.imwrite(path, img_to_save)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Pipeline for {base_name} completed in {elapsed:.2f}s, saved in {VIS_DIR}\")\n",
        "\n",
        "        # Display all steps\n",
        "        n = len(subdirs)\n",
        "        cols = 4\n",
        "        rows = (n + cols - 1) // cols\n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))\n",
        "        axes = axes.flatten()\n",
        "        for ax, (name, img) in zip(axes, subdirs.items()):\n",
        "            if len(img.shape) == 2:\n",
        "                display_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "            else:\n",
        "                display_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            ax.imshow(display_img)\n",
        "            ax.set_title(name)\n",
        "            ax.axis('off')\n",
        "        # hide extra axes\n",
        "        for ax in axes[n:]:\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "IMAGE_DIR = \"/content/non_missing_images\"\n",
        "VIS_DIR = \"pipeline_viz\"\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "os.makedirs(VIS_DIR, exist_ok=True)\n",
        "\n",
        "processor = EndoscopyImageProcessor()\n",
        "\n",
        "list_ids = [\n",
        "      'cla820gmms603071u3p4l07iv',\n",
        "]\n",
        "\n",
        "all_files = sorted([f for f in os.listdir(IMAGE_DIR) if f.lower().endswith(('.jpg'))])\n",
        "\n",
        "selected_files = []\n",
        "for img_id in list_ids:\n",
        "    found = False\n",
        "    for f in all_files:\n",
        "        if os.path.splitext(f)[0] == img_id:\n",
        "            selected_files.append(f)\n",
        "            found = True\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Không tìm thấy ảnh cho ID: {img_id}\")\n",
        "\n",
        "for img_file in os.listdir(IMAGE_DIR)[60:]:\n",
        "    img_path = os.path.join(IMAGE_DIR, img_file)\n",
        "    processor.visualize_pipeline(img_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1eMSfAAS5_A3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
